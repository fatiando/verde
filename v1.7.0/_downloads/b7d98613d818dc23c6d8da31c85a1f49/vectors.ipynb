{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Vector Data\n\nSome datasets have multiple vector components measured for each location, like\nthe East and West components of wind speed or GPS velocities. For example,\nlet's look at our sample GPS velocity data from the U.S. West coast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\nimport pyproj\n\nimport verde as vd\n\ndata = vd.datasets.fetch_california_gps()\n\n# We'll need to project the geographic coordinates to work with our Cartesian\n# classes/functions\nprojection = pyproj.Proj(proj=\"merc\", lat_ts=data.latitude.mean())\nproj_coords = projection(data.longitude.values, data.latitude.values)\n# This will be our desired grid spacing in degrees\nspacing = 12 / 60\n\nplt.figure(figsize=(6, 8))\nax = plt.axes(projection=ccrs.Mercator())\ncrs = ccrs.PlateCarree()\ntmp = ax.quiver(\n    data.longitude.values,\n    data.latitude.values,\n    data.velocity_east.values,\n    data.velocity_north.values,\n    scale=0.3,\n    transform=crs,\n    width=0.002,\n)\nax.quiverkey(tmp, 0.2, 0.15, 0.05, label=\"0.05 m/yr\", coordinates=\"figure\")\nax.set_title(\"GPS horizontal velocities\")\nvd.datasets.setup_california_gps_map(ax)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verde classes and functions are equipped to deal with vector data natively or\nthrough the use of the :class:`verde.Vector` class. Function and classes that\ncan take vector data as input will accept tuples as the ``data`` and\n``weights`` arguments. Each element of the tuple must be an array with the\ndata values for a component of the vector data. As with ``coordinates``,\n**the order of components must be** ``(east_component, north_component,\nup_component)``.\n\n\n## Blocked reductions\n\nOperations with :class:`verde.BlockReduce` and :class:`verde.BlockMean` can\nhandle multi-component data automatically. The reduction operation is applied\nto each data component separately. The blocked data and weights will be\nreturned in tuples as well following the same ordering as the inputs. This\nwill work for an arbitrary number of components.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use a blocked mean with uncertainty type weights\nreducer = vd.BlockMean(spacing=spacing * 111e3, uncertainty=True)\nblock_coords, block_data, block_weights = reducer.filter(\n    coordinates=proj_coords,\n    data=(data.velocity_east, data.velocity_north),\n    weights=(1 / data.std_east**2, 1 / data.std_north**2),\n)\nprint(len(block_data), len(block_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can convert the blocked coordinates back to longitude and latitude to plot\nwith Cartopy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "block_lon, block_lat = projection(*block_coords, inverse=True)\n\nplt.figure(figsize=(6, 8))\nax = plt.axes(projection=ccrs.Mercator())\ncrs = ccrs.PlateCarree()\ntmp = ax.quiver(\n    block_lon,\n    block_lat,\n    block_data[0],\n    block_data[1],\n    scale=0.3,\n    transform=crs,\n    width=0.002,\n)\nax.quiverkey(tmp, 0.2, 0.15, 0.05, label=\"0.05 m/yr\", coordinates=\"figure\")\nax.set_title(\"Block mean velocities\")\nvd.datasets.setup_california_gps_map(ax)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trends\n\nTrends can't handle vector data automatically, so you can't pass\n``data=(data.velocity_east, data.velocity_north)`` to\n:meth:`verde.Trend.fit`. To get around that, you can use the\n:class:`verde.Vector` class to create multi-component estimators and gridders\nfrom single component ones.\n\n:class:`~verde.Vector` takes an estimator/gridder for each data component and\nimplements the `gridder interface <gridder_interface>` for vector data,\nfitting each estimator/gridder given to a different component of the data.\n\nFor example, to fit a trend to our GPS velocities, we need to make a\n2-component vector trend:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trend = vd.Vector([vd.Trend(4), vd.Trend(1)])\nprint(trend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use the ``trend`` as if it were a regular :class:`verde.Trend` but\npassing in 2-component data to fit. This will fit each data component to a\ndifferent :class:`verde.Trend`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trend.fit(\n    coordinates=proj_coords,\n    data=(data.velocity_east, data.velocity_north),\n    weights=(1 / data.std_east**2, 1 / data.std_north**2),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each estimator can be accessed through the ``components`` attribute:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(trend.components)\nprint(\"East trend coefficients:\", trend.components[0].coef_)\nprint(\"North trend coefficients:\", trend.components[1].coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we call :meth:`verde.Vector.predict` or :meth:`verde.Vector.grid`, we'll\nget back predictions for two components instead of just one. Each prediction\ncomes from a different :class:`verde.Trend`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_east, pred_north = trend.predict(proj_coords)\n\n# Make histograms of the residuals\nplt.figure(figsize=(6, 5))\nax = plt.axes()\nax.set_title(\"Trend residuals\")\nax.hist(data.velocity_north - pred_north, bins=\"auto\", label=\"North\", alpha=0.7)\nax.hist(data.velocity_east - pred_east, bins=\"auto\", label=\"East\", alpha=0.7)\nax.legend()\nax.set_xlabel(\"Velocity (m/yr)\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the residuals are higher for the North component because of the\nlower degree polynomial.\n\nLet's make geographic grids of these trends.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "region = vd.get_region((data.longitude, data.latitude))\n\ngrid = trend.grid(\n    region=region,\n    spacing=spacing,\n    projection=projection,\n    dims=[\"latitude\", \"longitude\"],\n)\nprint(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, the names of the data components in the :class:`xarray.Dataset`\nare ``east_component`` and ``north_component``. This can be customized using\nthe ``data_names`` argument.\n\nNow we can map the trends.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(\n    1, 2, figsize=(9, 7), subplot_kw=dict(projection=ccrs.Mercator())\n)\ncrs = ccrs.PlateCarree()\ntitles = [\"East component trend\", \"North component trend\"]\ncomponents = [grid.east_component, grid.north_component]\nfor ax, component, title in zip(axes, components, titles):\n    ax.set_title(title)\n    maxabs = vd.maxabs(component)\n    tmp = component.plot.pcolormesh(\n        ax=ax,\n        vmin=-maxabs,\n        vmax=maxabs,\n        cmap=\"bwr\",\n        transform=crs,\n        add_colorbar=False,\n        add_labels=False,\n    )\n    cb = plt.colorbar(tmp, ax=ax, orientation=\"horizontal\", pad=0.05)\n    cb.set_label(\"meters/year\")\n    vd.datasets.setup_california_gps_map(ax, land=None, ocean=None)\n    ax.coastlines(color=\"white\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gridding\n\nYou can use :class:`verde.Vector` to create multi-component gridders out of\n:class:`verde.Spline` the same way as we did for trends. In this case, each\ncomponent is treated separately.\n\nWe can start by splitting the data into training and testing sets (see\n`model_selection`). Notice that :func:`verde.train_test_split` work for\nmulticomponent data automatically.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train, test = vd.train_test_split(\n    coordinates=proj_coords,\n    data=(data.velocity_east, data.velocity_north),\n    weights=(1 / data.std_east**2, 1 / data.std_north**2),\n    random_state=1,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can make a 2-component spline. Since :class:`verde.Vector` implements\n``fit``, ``predict``, and ``filter``, we can use it in a :class:`verde.Chain`\nto build a pipeline.\n\nWe need to use a bit of damping so that the weights can be taken into\naccount. Splines without damping provide a perfect fit to the data and ignore\nthe weights as a consequence.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "chain = vd.Chain(\n    [\n        (\"mean\", vd.BlockMean(spacing=spacing * 111e3, uncertainty=True)),\n        (\"trend\", vd.Vector([vd.Trend(1), vd.Trend(1)])),\n        (\"spline\", vd.Vector([vd.Spline(damping=1e-10), vd.Spline(damping=1e-10)])),\n    ]\n)\nprint(chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>Never generate the component gridders with ``[vd.Spline()]*2``. This will\n    result in each component being a represented by **the same Spline\n    object**, causing problems when trying to fit it to different components.</p></div>\n\nFitting the spline and gridding is exactly the same as what we've done\nbefore.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "chain.fit(*train)\n\n# Score on the test data\nprint(chain.score(*test))\n\ngrid = chain.grid(\n    region=region,\n    spacing=spacing,\n    projection=projection,\n    dims=[\"latitude\", \"longitude\"],\n)\nprint(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mask out the points too far from data and plot the gridded vectors.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid = vd.distance_mask(\n    (data.longitude, data.latitude),\n    maxdist=spacing * 2 * 111e3,\n    grid=grid,\n    projection=projection,\n)\n\nplt.figure(figsize=(6, 8))\nax = plt.axes(projection=ccrs.Mercator())\ntmp = ax.quiver(\n    grid.longitude.values,\n    grid.latitude.values,\n    grid.east_component.values,\n    grid.north_component.values,\n    scale=0.3,\n    transform=crs,\n    width=0.002,\n)\nax.quiverkey(tmp, 0.2, 0.15, 0.05, label=\"0.05 m/yr\", coordinates=\"figure\")\nax.set_title(\"Gridded velocities\")\nvd.datasets.setup_california_gps_map(ax)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPS/GNSS data\n\nFor some types of vector data, like GPS/GNSS displacements, the vector\ncomponents are coupled through elasticity. In these cases, elastic Green's\nfunctions can be used to achieve better interpolation results. The `Erizo\npackage <https://github.com/fatiando/erizo>`__ implements some of these\nGreen's functions.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>The :class:`verde.VectorSpline2D` class implemented an elastically\n    coupled Green's function but it is deprecated and will be removed in\n    Verde v2.0.0. Please use the implementation in the `Erizo\n    <https://github.com/fatiando/erizo>`__ package instead.</p></div>\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}