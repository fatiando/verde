{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# K-Fold cross-validation with blocks\n\nCross-validation scores for spatial data can be biased because observations are\ncommonly spatially autocorrelated (closer data points have similar values). One\nstrategy to reduce the bias is to split data along spatial blocks\n[Roberts_etal2017]_. Verde offers the cross-validator\n:class:`verde.BlockKFold`, which is a scikit-learn compatible version of k-fold\ncross-validation using spatial blocks.\n\nWhen splitting the data into training and testing sets,\n:class:`~verde.BlockKFold` first splits the data into spatial blocks and then\nsplits the blocks into folds. During k-fold cross-validation, one fold is used\nas the testing set while the rest are used for training. Since each block can\nhave a different number of data points, assigning the same number of blocks to\neach fold can lead to folds with very different numbers of data points.\nBy default, :class:`~verde.BlockKFold` takes care to balance the folds to have\napproximately equal number of data points.\nAlternatively, you can turn off balancing to have each fold contain the same\nnumber of blocks.\n\nThis example shows the data assigned to each of the first 3 folds of a blocked\nk-fold iteration, with and without balancing. Notice that the unbalanced folds\nhave very different numbers of data points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport verde as vd\n\n# Let's split the Baja California shipborne bathymetry data\ndata = vd.datasets.fetch_baja_bathymetry()\ncoordinates = (data.longitude, data.latitude)\n\n# Create cross-validators with blocks of 30 arc-minutes with shuffling enabled.\nspacing = 30 / 60\n# Set the random state so that these plots don't vary when we rerun the example\nrandom_state = 10\nkfold = vd.BlockKFold(spacing=spacing, shuffle=True, random_state=random_state)\n# Make another cross-validator with fold balancing turned off. Without\n# balancing, the folds can have very different number of data points in them\n# (which may bias the scores).\nkfold_unbalanced = vd.BlockKFold(\n    spacing=spacing,\n    shuffle=True,\n    random_state=random_state,\n    balance=False,\n)\n\n# The BlockKFold is compatible with scikit-learn, so instead of giving it a\n# coordinates tuple (like we use in Verde), we have to put the coordinates in a\n# feature matrix (X in scikit-learn jargon). Each column will have one of the\n# coordinate values. This is usually not required if using this cross-validator\n# with Verde functions and classes. You can pass it to verde.cross_val_score,\n# for example.\nfeature_matrix = np.transpose(coordinates)\n\n# Create the folds for the balanced and unbalanced cross-validators to show the\n# difference.\nbalanced = kfold.split(feature_matrix)\nunbalanced = kfold_unbalanced.split(feature_matrix)\n\n# Cartopy requires setting the coordinate reference system (CRS) of the\n# original data through the transform argument. Their docs say to use\n# PlateCarree to represent geographic data.\ncrs = ccrs.PlateCarree()\n\n# Make Mercator maps of the two cross-validator folds\nfig, axes = plt.subplots(\n    2,\n    3,\n    figsize=(12, 10),\n    subplot_kw=dict(projection=ccrs.Mercator()),\n    sharex=True,\n    sharey=True,\n)\nfor row, title, folds in zip(axes, [\"Balanced\", \"Unbalanced\"], [balanced, unbalanced]):\n    for i, (ax, fold) in enumerate(zip(row, folds)):\n        train, test = fold\n        ax.set_title(\"{} fold {} ({} testing points)\".format(title, i, test.size))\n        # Use an utility function to setup the tick labels and the land feature\n        vd.datasets.setup_baja_bathymetry_map(ax)\n        ax.plot(\n            coordinates[0][train],\n            coordinates[1][train],\n            \".b\",\n            markersize=1,\n            transform=crs,\n            label=\"Train\",\n        )\n        ax.plot(\n            coordinates[0][test],\n            coordinates[1][test],\n            \".r\",\n            markersize=1,\n            transform=crs,\n            label=\"Test\",\n        )\n# Place a legend on the first plot\naxes[0, 0].legend(loc=\"upper right\", markerscale=5)\nplt.subplots_adjust(\n    hspace=0.1, wspace=0.05, top=0.95, bottom=0.05, left=0.05, right=0.95\n)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}