{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nModel Selection\n===============\n\nThe Green's functions based interpolations in Verde are all linear regressions under the\nhood. This means that we can use some of the same tactics from\n:mod:`sklearn.model_selection` to evaluate our interpolator's performance. Once we have\na quantified measure of the quality of a given fitted gridder, we can use it to tune the\ngridder's parameters, like ``damping`` for a :class:`~verde.Spline`.\n\nVerde provides adaptations of common scikit-learn tools to work better with spatial\ndata. Let's use these tools to evaluate and tune a :class:`~verde.Spline` to grid our\nsample air temperature data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport itertools\nimport pyproj\nimport verde as vd\n\ndata = vd.datasets.fetch_texas_wind()\n\n# Use Mercator projection because Spline is a Cartesian gridder\nprojection = pyproj.Proj(proj=\"merc\", lat_ts=data.latitude.mean())\nproj_coords = projection(data.longitude.values, data.latitude.values)\n\nregion = vd.get_region((data.longitude, data.latitude))\n# The desired grid spacing in degrees (converted to meters using 1 degree approx. 111km)\nspacing = 15 / 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splitting the data\n------------------\n\nWe can't evaluate a gridder on the data that went into fitting it. The true test of a\nmodel is if it can correctly predict data that it hasn't seen before. scikit-learn has\nthe :func:`sklearn.model_selection.train_test_split` function to separate a dataset\ninto two parts: one for fitting the model (called *training* data) and a separate one\nfor evaluating the model (called *testing* data). Using it with spatial data would\ninvolve some tedious array conversions so Verde implements\n:func:`verde.train_test_split` which does the same thing but takes coordinates and\ndata arrays instead.\n\nThe split is done randomly so we specify a seed for the random number generator to\nguarantee that we'll get the same result every time we run this example. You probably\ndon't want to do that for real data. We'll keep 30% of the data to use for testing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train, test = vd.train_test_split(\n    proj_coords, data.air_temperature_c, test_size=0.3, random_state=0\n)\nprint(train)\nprint(test)\n\nplt.figure(figsize=(8, 6))\nax = plt.axes()\nax.set_title(\"Air temperature measurements for Texas\")\nax.plot(train[0][0], train[0][1], \".r\", label=\"train\")\nax.plot(test[0][0], test[0][1], \".b\", label=\"test\")\nax.legend()\nax.set_aspect(\"equal\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The returned ``train`` and ``test`` arguments are each tuples with the coordinates (in\na tuple) and a data array. They are in a format that can be easily passed to the\n:meth:`~verde.base.BaseGridder.fit` method of most gridders using Python's argument\nexpansion using the ``*`` symbol.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "chain = vd.Chain(\n    [\n        (\"reduce\", vd.BlockReduce(np.mean, spacing * 111e3)),\n        (\"trend\", vd.Trend(degree=1)),\n        (\"spline\", vd.Spline()),\n    ]\n)\nchain.fit(*train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the gridded result to see what it looks like. We'll mask out grid points\nthat are too far from any given data point.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mask = vd.distance_mask(\n    (data.longitude, data.latitude),\n    maxdist=3 * spacing * 111e3,\n    coordinates=vd.grid_coordinates(region, spacing=spacing),\n    projection=projection,\n)\ngrid = chain.grid(\n    region=region,\n    spacing=spacing,\n    projection=projection,\n    dims=[\"latitude\", \"longitude\"],\n    data_names=[\"temperature\"],\n).where(mask)\n\nplt.figure(figsize=(8, 6))\nax = plt.axes(projection=ccrs.Mercator())\nax.set_title(\"Gridded temperature\")\npc = ax.pcolormesh(\n    grid.longitude,\n    grid.latitude,\n    grid.temperature,\n    cmap=\"plasma\",\n    transform=ccrs.PlateCarree(),\n)\nplt.colorbar(pc).set_label(\"C\")\nax.plot(data.longitude, data.latitude, \".k\", markersize=1, transform=ccrs.PlateCarree())\nvd.datasets.setup_texas_wind_map(ax)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scoring\n--------\n\nGridders in Verde implement the :meth:`~verde.base.BaseGridder.score` method that\ncalculates the `R\u00b2 coefficient of determination\n<https://en.wikipedia.org/wiki/Coefficient_of_determination>`__\nfor a given comparison dataset (``test`` in our case). The R\u00b2 score is at most 1,\nmeaning a perfect prediction, but has no lower bound.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "score = chain.score(*test)\nprint(\"R\u00b2 score:\", score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's a good score meaning that our gridder is able to accurately predict data that\nwasn't used in the gridding algorithm.\n\nTuning\n------\n\n:class:`~verde.Spline` has many parameters that can be set to modify the final result.\nMainly the ``damping`` regularization parameter and the ``mindist`` \"fudge factor\"\nwhich smooths the solution. Would changing the default values give us a better score?\nWhat if we used a 2nd degree trend instead?\n\nWe can answer these questions by changing the values in our ``chain`` and\nre-evaluating the model score. Let's test the following combinations of parameters:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dampings = [None, 1e-8, 1e-6]\nmindists = [10e3, 100e3, 1000e3]\ndegrees = [1, 2, 3, 4]\n\n# Use itertools to create a list with all combinations of parameters to test\nparameter_sets = list(itertools.product(dampings, mindists, degrees))\nprint(\"Number of combinations:\", len(parameter_sets))\nprint(\"Combinations:\", parameter_sets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can loop over the combinations and collect the scores for each parameter set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = []\nfor damping, mindist, degree in parameter_sets:\n    chain.named_steps[\"spline\"].set_params(damping=damping, mindist=mindist)\n    chain.named_steps[\"trend\"].set_params(degree=degree)\n    score = chain.fit(*train).score(*test)\n    scores.append(score)\nprint(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The largest score will yield the best parameter combination.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "best = np.argmax(scores)\nprint(\"Best score:\", scores[best])\nprint(\"Best damping, mindist, and degree:\", parameter_sets[best])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We managed to get a slightly better score using the above configuration. That's not a\nhuge improvement but we also haven't tried that many parameter combinations.\n\nWe can now configure our chain with the best configuration and re-fit. We could also\nhave kept separate chains, each fit on a combination, to avoid having to fit again.\nSince this is a small dataset, it doesn't matter too much.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "damping, mindist, degree = parameter_sets[best]\nchain.named_steps[\"spline\"].set_params(damping=damping, mindist=mindist)\nchain.named_steps[\"trend\"].set_params(degree=degree)\nchain.fit(*train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can make a grid with the best configuration to see how it compares to our\nprevious result.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid_best = chain.grid(\n    region=region,\n    spacing=spacing,\n    projection=projection,\n    dims=[\"latitude\", \"longitude\"],\n    data_names=[\"temperature\"],\n).where(mask)\n\nplt.figure(figsize=(14, 8))\nfor i, title, grd in zip(range(2), [\"Defaults\", \"Tuned\"], [grid, grid_best]):\n    ax = plt.subplot(1, 2, i + 1, projection=ccrs.Mercator())\n    ax.set_title(title)\n    pc = ax.pcolormesh(\n        grd.longitude,\n        grd.latitude,\n        grd.temperature,\n        cmap=\"plasma\",\n        transform=ccrs.PlateCarree(),\n        vmin=data.air_temperature_c.min(),\n        vmax=data.air_temperature_c.max(),\n    )\n    plt.colorbar(pc, orientation=\"horizontal\", aspect=50, pad=0.05).set_label(\"C\")\n    ax.plot(\n        data.longitude, data.latitude, \".k\", markersize=1, transform=ccrs.PlateCarree()\n    )\n    vd.datasets.setup_texas_wind_map(ax)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that, for sparse data like these, smoother models tend to be better predictors.\nThis is a sign that you should probably not trust many of the short wavelength\nfeatures that we get from the defaults.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}