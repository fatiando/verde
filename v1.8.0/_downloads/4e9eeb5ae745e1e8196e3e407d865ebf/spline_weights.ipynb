{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Gridding with splines and weights\n\nAn advantage of using the Green's functions based :class:`verde.Spline` over\n:class:`verde.ScipyGridder` is that you can assign weights to the data to\nincorporate the data uncertainties or variance into the gridding. In this\nexample, we'll see how to combine :class:`verde.BlockMean` to decimate the data\nand use weights based on the data uncertainty during gridding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\nimport pyproj\nfrom matplotlib.colors import PowerNorm\n\nimport verde as vd\n\n# We'll test this on the California vertical GPS velocity data because it comes\n# with the uncertainties\ndata = vd.datasets.fetch_california_gps()\ncoordinates = (data.longitude.values, data.latitude.values)\n\n# Use a Mercator projection for our Cartesian gridder\nprojection = pyproj.Proj(proj=\"merc\", lat_ts=data.latitude.mean())\n\n# Now we can chain a block weighted mean and weighted spline together. We'll\n# use uncertainty propagation to calculate the new weights from block mean\n# because our data vary smoothly but have different uncertainties.\nspacing = 5 / 60  # 5 arc-minutes\nchain = vd.Chain(\n    [\n        (\"mean\", vd.BlockMean(spacing=spacing * 111e3, uncertainty=True)),\n        (\"spline\", vd.Spline(damping=1e-10)),\n    ]\n)\nprint(chain)\n\n# Split the data into a training and testing set. We'll use the training set to\n# grid the data and the testing set to validate our spline model. Weights need\n# to 1/uncertainty**2 for the error propagation in BlockMean to work.\ntrain, test = vd.train_test_split(\n    projection(*coordinates),\n    data.velocity_up,\n    weights=1 / data.std_up**2,\n    random_state=0,\n)\n# Fit the model on the training set\nchain.fit(*train)\n# And calculate an R^2 score coefficient on the testing set. The best possible\n# score (perfect prediction) is 1. This can tell us how good our spline is at\n# predicting data that was not in the input dataset.\nscore = chain.score(*test)\nprint(\"\\nScore: {:.3f}\".format(score))\n\n# Create a grid of the vertical velocity and mask it to only show points close\n# to the actual data.\nregion = vd.get_region(coordinates)\ngrid_full = chain.grid(\n    region=region,\n    spacing=spacing,\n    projection=projection,\n    dims=[\"latitude\", \"longitude\"],\n    data_names=[\"velocity\"],\n)\ngrid = vd.convexhull_mask(\n    (data.longitude, data.latitude), grid=grid_full, projection=projection\n)\n\nfig, axes = plt.subplots(\n    1, 2, figsize=(9, 7), subplot_kw=dict(projection=ccrs.Mercator())\n)\ncrs = ccrs.PlateCarree()\n# Plot the data uncertainties\nax = axes[0]\nax.set_title(\"Data uncertainty\")\n# Plot the uncertainties in mm/yr and using a power law for the color scale to\n# highlight the smaller values\npc = ax.scatter(\n    *coordinates,\n    c=data.std_up * 1000,\n    s=20,\n    cmap=\"magma\",\n    transform=crs,\n    norm=PowerNorm(gamma=1 / 2)\n)\ncb = plt.colorbar(pc, ax=ax, orientation=\"horizontal\", pad=0.05)\ncb.set_label(\"uncertainty [mm/yr]\")\nvd.datasets.setup_california_gps_map(ax, region=region)\n# Plot the gridded velocities\nax = axes[1]\nax.set_title(\"Weighted spline interpolated velocity\")\nmaxabs = vd.maxabs(data.velocity_up) * 1000\npc = (grid.velocity * 1000).plot.pcolormesh(\n    ax=ax,\n    cmap=\"seismic\",\n    vmin=-maxabs,\n    vmax=maxabs,\n    transform=crs,\n    add_colorbar=False,\n    add_labels=False,\n)\ncb = plt.colorbar(pc, ax=ax, orientation=\"horizontal\", pad=0.05)\ncb.set_label(\"vertical velocity [mm/yr]\")\nax.scatter(*coordinates, c=\"black\", s=0.5, alpha=0.1, transform=crs)\nvd.datasets.setup_california_gps_map(ax, region=region)\nax.coastlines()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}